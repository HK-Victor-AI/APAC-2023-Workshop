{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNH4ds+KpOxG3cAExjMUuca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HK-Victor-AI/APAC-2023-Workshop/blob/main/Instruction_answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is an example for Instruction Answering.\n",
        "# You give an instruction to the LLM and the LLM makes the responses\n",
        "# Model used: llama-2-13b-chat.Q4_0.gguf\n",
        "# Model: Llama 2,\n",
        "# Size: 13B,\n",
        "# Model type: Chat model\n",
        "# Quantization: 4bit, native method\n",
        "# Model Format: gguf\n",
        "\n",
        "# First step: GET A GPU !!!\n",
        "# Then\n",
        "# Let us install langchain and llama-cpp-python."
      ],
      "metadata": {
        "id": "QVECpMJqLvGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "npMLUhM-Lnj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG1tp3oxL4qg",
        "outputId": "51022d00-76c9-4b36-946f-2062cc95fc41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.308-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.40 (from langchain)\n",
            "  Downloading langsmith-0.0.41-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.308 langsmith-0.0.41 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZO6hgFLsLqbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export LLAMA_CUBLAS=1\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ4UuiVqMuXz",
        "outputId": "49392e53-0290-4a72-8553-25f1e4b51afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.11.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.11-cp310-cp310-manylinux_2_35_x86_64.whl size=6423560 sha256=bca281e087a4bc6e4bd48e5d3b17af5e19aa3ca409904013c796eb307b124624\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/42/77/a3ab0d02700427ea364de5797786c0272779dce795f62c3bc2\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the chat model!\n",
        "!wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj7-_-1SP3QQ",
        "outputId": "d432ce03-fc35-4304-a740-3ceda7ac36e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-05 03:39:35--  https://huggingface.co/TheBloke/Llama-2-13B-GGUF/resolve/main/llama-2-13b.Q4_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.23, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b1/be/b1bebadea37cd4dd7655da740ed74e9a825af7c9ffddf51690f59fb89df02706/283fc12bcea5638fc82bcd038f0d19eaf0ebdc7fec9e4536d3e8063c1cc84548?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b.Q4_0.gguf%3B+filename%3D%22llama-2-13b.Q4_0.gguf%22%3B&Expires=1696736375&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjczNjM3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iMS9iZS9iMWJlYmFkZWEzN2NkNGRkNzY1NWRhNzQwZWQ3NGU5YTgyNWFmN2M5ZmZkZGY1MTY5MGY1OWZiODlkZjAyNzA2LzI4M2ZjMTJiY2VhNTYzOGZjODJiY2QwMzhmMGQxOWVhZjBlYmRjN2ZlYzllNDUzNmQzZTgwNjNjMWNjODQ1NDg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=xucyLBh-5zBUBHXBq0h%7EIDX1-%7E8e-WLdiwZAsl8mfZ2B5GZ%7Es4D60X3Lqp104U3wUsZODuH6bZhwRPC3EKP2SDXGIzr6UfFOmX1zFonJZM9Zj-BzfOUpMCXa1o0oWqR5SnMM3JRGBnPkBw5DWF9vaU4FIX96RZDx8j3rkTrXPXwD08tgMLxyCLxUeWE%7EGgNkmbVcEmpxwfvcXyrQQHd8Z8eNUd4zQP0ZX5riyuBdq8GtBdNfEl3a3rGx%7ExjFYI6GV7aa7jwIcH-jdsJL76au5jxSfNvHtPE4V7nkJQZWthfR2WrPVI7XjvzxrCdwAiSdbvRHUQxYhAl8qzigeLZmRA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-10-05 03:39:35--  https://cdn-lfs.huggingface.co/repos/b1/be/b1bebadea37cd4dd7655da740ed74e9a825af7c9ffddf51690f59fb89df02706/283fc12bcea5638fc82bcd038f0d19eaf0ebdc7fec9e4536d3e8063c1cc84548?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b.Q4_0.gguf%3B+filename%3D%22llama-2-13b.Q4_0.gguf%22%3B&Expires=1696736375&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NjczNjM3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iMS9iZS9iMWJlYmFkZWEzN2NkNGRkNzY1NWRhNzQwZWQ3NGU5YTgyNWFmN2M5ZmZkZGY1MTY5MGY1OWZiODlkZjAyNzA2LzI4M2ZjMTJiY2VhNTYzOGZjODJiY2QwMzhmMGQxOWVhZjBlYmRjN2ZlYzllNDUzNmQzZTgwNjNjMWNjODQ1NDg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=xucyLBh-5zBUBHXBq0h%7EIDX1-%7E8e-WLdiwZAsl8mfZ2B5GZ%7Es4D60X3Lqp104U3wUsZODuH6bZhwRPC3EKP2SDXGIzr6UfFOmX1zFonJZM9Zj-BzfOUpMCXa1o0oWqR5SnMM3JRGBnPkBw5DWF9vaU4FIX96RZDx8j3rkTrXPXwD08tgMLxyCLxUeWE%7EGgNkmbVcEmpxwfvcXyrQQHd8Z8eNUd4zQP0ZX5riyuBdq8GtBdNfEl3a3rGx%7ExjFYI6GV7aa7jwIcH-jdsJL76au5jxSfNvHtPE4V7nkJQZWthfR2WrPVI7XjvzxrCdwAiSdbvRHUQxYhAl8qzigeLZmRA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.144.113, 18.154.144.90, 18.154.144.108, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.144.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7365834624 (6.9G) [binary/octet-stream]\n",
            "Saving to: ‘llama-2-13b.Q4_0.gguf’\n",
            "\n",
            "llama-2-13b.Q4_0.gg 100%[===================>]   6.86G  80.7MB/s    in 79s     \n",
            "\n",
            "2023-10-05 03:40:54 (88.7 MB/s) - ‘llama-2-13b.Q4_0.gguf’ saved [7365834624/7365834624]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/llama-2-13b-chat.Q4_0.gguf\", # location of the model\n",
        "    temperature=0.75,                 # temperature\n",
        "    max_tokens=2000,                 # Max. number of tokens to be generated\n",
        "    top_p=0.9,                    # top_p = 0.9\n",
        "    top_k=30,                     # top_k = 30\n",
        "    n_gpu_layers=43,                 # number of layers to offload to GPU\n",
        "    verbose=True, # Verbose is required to pass to the callback manager\n",
        "    n_batch=200,          # number of token generation in parallel\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0APaGROMRMC",
        "outputId": "7edd7fd4-fa1d-48b0-f5df-ced892e98f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8PNez0eOP08R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a251f874-37a6-4957-f299-f49324478fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  5 03:52:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P0    28W /  70W |   7949MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"what is water?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ScRdcYAQ72XM",
        "outputId": "39383ada-d963-4c38-9196-478b6457647f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nWater is a clear, colorless, odorless liquid that is essential for all known forms of life. It is the most abundant substance on Earth and makes up approximately 71% of the planet's surface. Water is composed of two hydrogen atoms and one oxygen atom, with the chemical formula H2O.\\n\\nWater is a vital component of all living organisms, and it plays a crucial role in many bodily functions, such as regulating body temperature, transporting nutrients and oxygen to cells, and removing waste products. Water also has important economic, social, and cultural significance, and it is essential for agriculture, industry, and recreation.\\n\\nThere are several different forms of water, including:\\n\\n1. Freshwater: This is water that is not salty and is found in rivers, lakes, and underground aquifers.\\n2. Saltwater: Also known as seawater, this is water that contains high levels of salt and is found in oceans and seas.\\n3. Brackish water: This is water that is more salty than freshwater but less salty than seawater, and it is often found in estuaries and coastal areas.\\n4. Distilled water: This is water that has been purified through distillation, a process that removes impurities and minerals from the water.\\n5. Tap water: This is water that is supplied to homes and businesses through a network of pipes and is treated to remove impurities and pathogens.\\n6. Bottled water: This is water that is packaged in bottles and sold for consumption on the go or at home.\\n\\nOverall, water is a vital and essential substance that is necessary for all forms of life on Earth.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"plan a 2 days trip in Singapore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "j-0xjdaf9kCk",
        "outputId": "f2c08987-7002-4384-c1cd-43cb4556c1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'?\\n\\nI would like to visit some of the famous landmarks and attractions in Singapore, but I only have 2 days. Can you help me plan my itinerary? Here are some of the places I would like to visit:\\n\\n1. Gardens by the Bay - I want to see the Supertree Grove and the Flower Dome and Cloud Forest Domes.\\n2. Marina Bay Sands - I want to take a photo with the iconic hotel and enjoy the light and water show at night.\\n3. Merlion - I want to see the famous statue and take a photo with it.\\n4. Singapore Flyer - I want to ride the giant Ferris wheel and enjoy the panoramic view of the city.\\n5. Chinatown - I would like to explore the colorful streets and try some delicious street food.\\n6. Little India - I would like to experience the vibrant Indian culture and try some authentic Indian cuisine.\\n7. Haw Par Villa - I want to see the largest theme park in Singapore and enjoy the Chinese mythology-themed rides and attractions.\\n8. Clarke Quay - I would like to visit the nightlife district and enjoy the bars, clubs, and live music performances.\\n\\nCan you help me plan my itinerary for my 2 days in Singapore? Thank you!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = '''\n",
        "1. Gardens by the Bay - I want to see the Supertree Grove and the Flower Dome and Cloud Forest Domes.\n",
        "2. Marina Bay Sands - I want to take a photo with the iconic hotel and enjoy the light and water show at night.\n",
        "3. Merlion - I want to see the famous statue and take a photo with it.\n",
        "4. Singapore Flyer - I want to ride the giant Ferris wheel and enjoy the panoramic view of the city.\n",
        "5. Chinatown - I would like to explore the colorful streets and try some delicious street food.\n",
        "6. Little India - I would like to experience the vibrant Indian culture and try some authentic Indian cuisine.\n",
        "7. Haw Par Villa - I want to see the largest theme park in Singapore and enjoy the Chinese mythology-themed rides and attractions.\n",
        "8. Clarke Quay - I would like to visit the nightlife district and enjoy the bars, clubs, and live music performances.\n",
        "'''\n",
        "llm(\"Please summarize the following passage in 50 words. Passage: \" + txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "PolJagGH-sYt",
        "outputId": "adc964d7-addf-43d3-d2ba-731be3f34b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThank you! Here is the summary of the passage in 50 words:\\n\\nI want to see Supertree Grove, Flower Dome, Cloud Forest Domes, Marina Bay Sands light show, Merlion, Singapore Flyer, Chinatown street food, Little India, Haw Par Villa theme park, and Clarke Quay nightlife.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}